{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Autograd in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto grad is functionality within pytorch that allows you to automatically keep the derivatives of the functions that are being called in your machine learning workflow. Autograd allows us to store the gradient for data objects in a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x**2\n",
    "z = y*y*5\n",
    "z = z.mean()\n",
    "z.backward() # calculates gradients for z with respect to x\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## removing the gradient attribute\n",
    "\n",
    "x.requires_grad_(False) # the opposite switches on the autograd tracking\n",
    "x.detach()\n",
    "\n",
    "with torch.no_grad():\n",
    "    pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a simple examples: the eucledian norm of a vector is $f(x) = x_1^2 + x_2^2 + x_3^2 + \\dots + x_n^2$ the gradient of this calculation is a vector of all the partial derivatives of the input times 2 (don't trust, verify this yourself). Therefore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor(14., grad_fn=<DotBackward0>)\n",
      "tensor([0., 2., 4., 6.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(4.0 , requires_grad=True)\n",
    "print(x.grad)\n",
    "\n",
    "y = torch.dot(x,x)\n",
    "print(y)\n",
    "\n",
    "y.backward()\n",
    "\n",
    "print(x.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('AI_Lab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38f3d14fe18daaf48a7acb4f925e655122b914ef7e792f38853c14d2a42aac38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
